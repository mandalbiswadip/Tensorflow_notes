{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "professional-hunger",
   "metadata": {},
   "source": [
    "## <center>Automatic Differentiation</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-occasions",
   "metadata": {},
   "source": [
    "Calculating gradients are crucials in Machine Learning as they are necessary for optimizing the loss functions. There are few ways of calculating the gradients:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-joseph",
   "metadata": {},
   "source": [
    "<u>**Symbolic Differentiation**</u>\n",
    "Symbolic differentiations are the most common way of calculating gradients. You can apply the law of derivatives to differentiate a function and get the derivative functions. Here is how a typical result for symbolic differentiation look like. As I menetioned, they can be calucalted by doing tedius calculations. Softwares like Mathematica use this particular method. \n",
    "\n",
    "![Images](https://raw.githubusercontent.com/mandalbiswadip/Tensorflow_two_notes/master/resources/symbolic_diff.png?token=AEG7MVC4BTST4SBGJIN47VLAJL22C)\n",
    "\n",
    "**Source: [Mathematica](https://www.wolfram.com/mathematica/)**<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-asset",
   "metadata": {},
   "source": [
    "**<u>Numerical Differentiation</u>**\n",
    "Numerical differentitation is another technique to estimate gradients. The simplest and most popular way is to use the **finite difference** method:\n",
    "![finite difference](https://raw.githubusercontent.com/mandalbiswadip/Tensorflow_two_notes/master/resources/finite_difference.png?token=AEG7MVA4MEVSHQVFDZP4RHDAJL234)\n",
    "\n",
    "Source: [Wikipedia](https://en.wikipedia.org/wiki/Finite_difference_method)\n",
    "\n",
    "If one uses a small enough `h`, gradient at point `x=a` can be estimated. Note that we don't have to actually differentiate the function like we do for symbolic differentiation. We just need to know the value of `f(x)` in the neighbourhood of `a`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-franklin",
   "metadata": {},
   "source": [
    "**What is Automatic Differentiation ?**\n",
    "\n",
    "Automatic Differentiation is a technique to calculate gradients. This is done in tensorflow using the computational graph. Each **node** in the graph represent a tensorflow operation and edges represent tensors. It is possible using the **chain rule** of differentiation to calculate local gradients of each node and multiply the gradients using the chain rule to get the actual gradient. \n",
    "\n",
    "Here is an example. Its shows how automatic differentitation is calculated and flows through for using the **chain rule**\n",
    "\n",
    "\n",
    "![Images](https://raw.githubusercontent.com/mandalbiswadip/Tensorflow_two_notes/master/resources/derivative_autodiff.png?token=AEG7MVH5IWWF4CRIUAMV26TAJL25S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-palestinian",
   "metadata": {},
   "source": [
    "## Using AutoDiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-cyprus",
   "metadata": {},
   "source": [
    "### **Gradient Tapes**\n",
    "\n",
    "Gradient tapes are essential to computing gradients in tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "written-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "amended-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-shelf",
   "metadata": {},
   "source": [
    "You can think of ```GradientTape``` as a recorder or a tape that records or watches the operations(or equations to be more generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "collective-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    \n",
    "    y = x**3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-ability",
   "metadata": {},
   "source": [
    "Now we can compute the gradient of `y` with respect to `x` at `x=100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "major-spoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30000.0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(target=y, sources=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-enforcement",
   "metadata": {},
   "source": [
    "at `x=100`<br> `dy/dx = 3*x^2 = 3*100^2 = 30000`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-journalism",
   "metadata": {},
   "source": [
    "We can pass multiple variables and get multiple gradients for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "impressive-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(10.)\n",
    "z = tf.Variable(4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "confused-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    \n",
    "    y = x**3 + z**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "editorial-alabama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=300.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(target=y, sources=[x, z])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-opinion",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**partial derivative of y with respect to x = 3xx^2 = 3x10^2 = 300.0**<br>\n",
    "**partial derivative of y with respect to z = 2xz = 2x4 = 8.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-circle",
   "metadata": {},
   "source": [
    "The gradients can be calculated with respect to multi dimensional arrays as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "rational-trash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float64, numpy=\n",
       "array([[0.85733164, 0.72450839, 0.01000471, 0.53435523],\n",
       "       [0.8112967 , 0.8668377 , 0.02962584, 0.92548695],\n",
       "       [0.77581414, 0.59835021, 0.65323683, 0.44299535]])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(np.random.random((3,4)))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "killing-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    \n",
    "    y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "czech-region",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float64, numpy=\n",
       "array([[1.71466328, 1.44901678, 0.02000943, 1.06871045],\n",
       "       [1.6225934 , 1.7336754 , 0.05925167, 1.85097391],\n",
       "       [1.55162829, 1.19670042, 1.30647367, 0.8859907 ]])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(target=y, sources=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-antarctica",
   "metadata": {},
   "source": [
    "The gradient refers to the following matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-cargo",
   "metadata": {},
   "source": [
    "\n",
    "![Images](../resources/download.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-livestock",
   "metadata": {},
   "source": [
    "The gradient shape will be the Variable shape. In this case it's `(3,4)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-festival",
   "metadata": {},
   "source": [
    "## tf.GradientTape.watch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-causing",
   "metadata": {},
   "source": [
    "`tf.GradientTape.watch` is used if you want to calculate gradients for `Tensors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "decimal-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fancy-activity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=27.0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = x**3\n",
    "\n",
    "tape.gradient(y,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-manner",
   "metadata": {},
   "source": [
    "### Important Flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-semiconductor",
   "metadata": {},
   "source": [
    "`watch_accessed_variables`:<br>\n",
    "By setting this variable False, you can bypass the defualt behaviour of considering all `tf.Variable`s for gradient. You can manually watch variable to using `tf.GradientTape.watch(x)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-least",
   "metadata": {},
   "source": [
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "interesting-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = tf.Variable(1.)\n",
    "y = tf.Variable(20.)\n",
    "\n",
    "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "    tape.watch(x)\n",
    "    f = 3*y**2 + 4*x**3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-safety",
   "metadata": {},
   "source": [
    "The following will produce valid output \n",
    "```\n",
    "tape.gradient(target=f, sources=x)\n",
    ">> <tf.Tensor: shape=(), dtype=float32, numpy=12.0>\n",
    "```\n",
    "While this will raise an error\n",
    "```\n",
    "tape.gradient(target=f, sources=y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-excerpt",
   "metadata": {},
   "source": [
    "`persistent`<br>\n",
    "If you want to use the same tape to calculate the gradient multiple times using the `persistent = True` flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-notification",
   "metadata": {},
   "source": [
    "#### **If the target variable is matrix, GradientTape computes the gradient with respect to sum of the target variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "mechanical-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(5.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "     y = [3., 4.]*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "strange-findings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(target=y, sources=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-audience",
   "metadata": {},
   "source": [
    "### Important Note:\n",
    "**Control flow**\n",
    "\n",
    "As the gradients of the operations are calculated independently, control flow can handled by gradient tapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-tunisia",
   "metadata": {},
   "source": [
    "## Example of Gradient Descent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-purchase",
   "metadata": {},
   "source": [
    "We try to optimize the following functions using gradient tapes: `y = 4x^2 + 100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "pointed-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "violent-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dutch-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "permanent-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "vital-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        y = 4*x**2 + 100\n",
    "    \n",
    "    grad = tape.gradient(y,x)\n",
    "    x = x - lr*grad\n",
    "    x_data.append(x.numpy())\n",
    "    y_data.append(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "raising-adelaide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=100.23665>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "early-labor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.24321193>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-occasion",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "destroyed-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "internal-beginning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7290ed2390>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_data, y_data, alpha=0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "approved-cisco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=100.23665>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-retrieval",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_keyword",
   "language": "python",
   "name": "bert_keyword"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "collective-battlefield",
   "metadata": {},
   "source": [
    "We can train models using keras Models. The first step is to define your model by inheriting from the `tf.keras.Model`. This can make use of defined or already available layers in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "liked-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class Dense(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, out_features, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.out_features = out_features\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(\n",
    "            tf.random.normal([input_shape[-1], self.out_features]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n",
    "\n",
    "    def call(self, x):\n",
    "        y = tf.matmul(x, self.w) + self.b\n",
    "        return tf.nn.relu(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nutritional-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, name=\"mymodel\"):\n",
    "        super().__init__()\n",
    "        self.dense = Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.dense(x)\n",
    "\n",
    "\n",
    "sequential_model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "responsible-festival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MyModel at 0x7f10d82265d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-lawrence",
   "metadata": {},
   "source": [
    "Now, if you think about it `Model` instances already contains to a deep learning architecture with trainable variables. The `call` function defines the forward pass of the Deep Learning Network and the gradients are obviously taken care by tensorflow under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-leather",
   "metadata": {},
   "source": [
    "If you have a set of inputs and outputs, the Netwrok can be trained/optimized for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-alliance",
   "metadata": {},
   "source": [
    "#### The following functions allow us to traine the Model on a dataset. We will discuss more about these in the `Keras API` section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-thinking",
   "metadata": {},
   "source": [
    "```\n",
    "model.compile(...)\n",
    "model.fit(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-victorian",
   "metadata": {},
   "source": [
    "`model.compile()`: It set's the parameters for training. Parameters include optimizer, loss, metrices\n",
    "    \n",
    "Note: There is also a `run_eagerly` parameter in this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-underwear",
   "metadata": {},
   "source": [
    "optimizer='rmsprop',\n",
    "loss=None,\n",
    "metrics=None,\n",
    "loss_weights=None,\n",
    "weighted_metrics=None,\n",
    "run_eagerly=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "frequent-verse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_model.dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-letter",
   "metadata": {},
   "source": [
    "`model.fit()`: This trains the model. We have learnt how to train/optimize using GradientTape. Keras follows similar steps under the hood to train models. \n",
    "\n",
    "Here is a screenshot of under the hood implementation of one step of the fit layer\n",
    "\n",
    "![train_step](../resources/train_step.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "every-static",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow._api.v2.config' from '/home/bxm200000/anaconda3/envs/bert_keyword/lib/python3.7/site-packages/tensorflow/_api/v2/config/__init__.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-confidence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_keyword",
   "language": "python",
   "name": "bert_keyword"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
